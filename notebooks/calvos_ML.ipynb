{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precición de calvicie \n",
    "\n",
    "El IA Project 2 consiste en realizar desplegar un modelo en streamlit. Nuestro equipo a elegido el dataset [Hair Health Prediction](https://www.kaggle.com/datasets/amitvkulkarni/hair-health) para predecir si se te está cayendo el pelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports y acercamiento al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.9.6)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"/Users/jorgemolto/Documents/PARA/01-Projects/EDEM/MIA/MIA PROJECTS/BALD_PREDICTION/venv/bin/python\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.8' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Load dependencies for loading data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Import dependencies for pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Predict Hair Fall.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors Contributing to Baldness\n",
    "\n",
    "1. **Genetics**:  \n",
    "   Indicates whether the individual has a family history of baldness (Yes/No).\n",
    "\n",
    "2. **Hormonal Changes**:  \n",
    "   Indicates whether the individual has experienced hormonal changes (Yes/No).\n",
    "\n",
    "3. **Medical Conditions**:  \n",
    "   Lists specific medical conditions that may contribute to baldness, such as:\n",
    "   - Alopecia Areata  \n",
    "   - Thyroid Problems  \n",
    "   - Scalp Infection  \n",
    "   - Psoriasis  \n",
    "   - Dermatitis  \n",
    "\n",
    "4. **Medications & Treatments**:  \n",
    "   Lists medications and treatments that may lead to hair loss, including:\n",
    "   - Chemotherapy  \n",
    "   - Heart Medication  \n",
    "   - Antidepressants  \n",
    "   - Steroids  \n",
    "\n",
    "5. **Nutritional Deficiencies**:  \n",
    "   Lists nutritional deficiencies that may contribute to hair loss, such as:\n",
    "   - Iron deficiency  \n",
    "   - Vitamin D deficiency  \n",
    "   - Biotin deficiency  \n",
    "   - Omega-3 fatty acid deficiency  \n",
    "\n",
    "6. **Stress**:  \n",
    "   Indicates the stress level of the individual (Low/Moderate/High).\n",
    "\n",
    "7. **Age**:  \n",
    "   Represents the age of the individual.\n",
    "\n",
    "8. **Poor Hair Care Habits**:  \n",
    "   Indicates whether the individual practices poor hair care habits (Yes/No).\n",
    "\n",
    "9. **Environmental Factors**:  \n",
    "   Indicates whether the individual is exposed to environmental factors that may contribute to hair loss (Yes/No).\n",
    "\n",
    "10. **Smoking**:  \n",
    "    Indicates whether the individual smokes (Yes/No).\n",
    "\n",
    "11. **Weight Loss**:  \n",
    "    Indicates whether the individual has experienced significant weight loss (Yes/No).\n",
    "\n",
    "12. **Baldness (Target)**:  \n",
    "    Binary variable indicating the presence (1) or absence (0) of baldness in the individual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include='object').columns\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Genetics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data['Hormonal Changes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Medical Conditions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Medical Conditions\"] == \"No Data\", \"Medical Conditions\"] = \"No CondMedicas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Medications & Treatments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Medications & Treatments\"] == \"No Data\", \"Medications & Treatments\"] = \"No Medications\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Nutritional Deficiencies \"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"Nutritional Deficiencies \"] == \"No Data\", \"Nutritional Deficiencies \"] = \"No Deficiencies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Stress\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Poor Hair Care Habits \"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Environmental Factors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Smoking\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data[\"Weight Loss \"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = data[\"Hair Loss\"].value_counts()\n",
    "\n",
    "plt.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette(\"Set2\", len(label_counts)))\n",
    "plt.title('0: no presencia de caida, 1: caida')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()\n",
    "\n",
    "# Mostrar los conteos de cada etiqueta\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar una red neuronal. Por tanto, vamos a tratar los datos para ello. No hará falta una ingeniería de características porque es la propia red la que se encarga de ello. \n",
    "\n",
    "Las transformcaiones a hacer son las siguientes: \n",
    "- Genetics, hormonal changes, Poor Hair Care Habits, Environmental Factors, Smoking, Weight Loss: y/n to 0/1\n",
    "\n",
    "- Medical Conditions, Medications & Treatments, Nutritional Deficiencies: one hot encoding \n",
    "\n",
    "- Stress: moderate, high, low -> 0,1,2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_yes_no = {\n",
    "    \"Yes\": 1,\n",
    "    \"No\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colums_yes_no = [\"Genetics\" ,\"Hormonal Changes\", \"Poor Hair Care Habits \", \"Environmental Factors\", \"Smoking\", \"Weight Loss \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_onehotencoder = [\"Medical Conditions\", \"Medications & Treatments\", \"Nutritional Deficiencies \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar por las columnas y mapear los valores\n",
    "for col in colums_yes_no:\n",
    "    if col in data.columns:  # Verifica que la columna exista\n",
    "        data[col] = data[col].map(map_yes_no)\n",
    "    else:\n",
    "        print(f\"Columna {col} no encontrada en el dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar el codificador\n",
    "encoder = OneHotEncoder()  # sparse=False para obtener una matriz densa\n",
    "for col in columns_onehotencoder:\n",
    "    \n",
    "    # Ajustar y transformar la columna 'col'\n",
    "    encoded = encoder.fit_transform(data[[col]]).toarray()\n",
    "    # Convertir el resultado en un DataFrame\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.categories_[0])\n",
    "\n",
    "    # Concatenar el DataFrame original con las columnas codificadas\n",
    "    data = pd.concat([data, encoded_df], axis=1)\n",
    "    \n",
    "    data.drop(col, axis=1, inplace=True)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_stres = {\n",
    "    \"Low\": 0,\n",
    "    \"Moderate\": 1,\n",
    "    \"High\": 2\n",
    "}\n",
    "data[\"Stress\"] = data[\"Stress\"].map(map_stres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input variables from output label\n",
    "X = data.drop(\"Hair Loss\", axis=1)\n",
    "y = data[\"Hair Loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data to improve stability while training\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in training and validation partitions\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val,\n",
    "                                                  test_size=0.5, stratify=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sizes of partitions\n",
    "print(\"Size of training data: \", X_train.shape)\n",
    "print(\"Size of training labels: \", y_train.shape)\n",
    "print(\"Size of validation data: \", X_val.shape)\n",
    "print(\"Size of validation labels: \", y_val.shape)\n",
    "print(\"Size of test labels: \", X_test.shape)\n",
    "print(\"Size of test labels: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestClassifier()\n",
    "f1_scorer = cross_val_score(RF, X_train, y_train, cv=5)\n",
    "media_f1 = f1_scorer.mean()\n",
    "# Intervalo de confianza con nivel de confianza 95%\n",
    "ci_95 = stats.t.interval(0.95, len(f1_scorer)-1, loc=media_f1, scale=stats.sem(f1_scorer))\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"F1-Score medio: {media_f1:.4f}\")\n",
    "print(f\"Intervalo de confianza del 95%: ({ci_95[0]:.4f}, {ci_95[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = SVC()\n",
    "f1_scorer = cross_val_score(sv, X_train, y_train, cv=5)\n",
    "media_f1 = f1_scorer.mean()\n",
    "# Intervalo de confianza con nivel de confianza 95%\n",
    "ci_95 = stats.t.interval(0.95, len(f1_scorer)-1, loc=media_f1, scale=stats.sem(f1_scorer))\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"F1-Score medio: {media_f1:.4f}\")\n",
    "print(f\"Intervalo de confianza del 95%: ({ci_95[0]:.4f}, {ci_95[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "f1_scorer = cross_val_score(gb, X_train, y_train, cv=5)\n",
    "media_f1 = f1_scorer.mean()\n",
    "# Intervalo de confianza con nivel de confianza 95%\n",
    "ci_95 = stats.t.interval(0.95, len(f1_scorer)-1, loc=media_f1, scale=stats.sem(f1_scorer))\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"F1-Score medio: {media_f1:.4f}\")\n",
    "print(f\"Intervalo de confianza del 95%: ({ci_95[0]:.4f}, {ci_95[1]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentación \n",
    "\n",
    "Partimos de las métricas de modelos base procedemos a realizar experimentos a ver si mejoran los resultados. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(data, target_column = 'Hair Loss'):\n",
    "    \"\"\"\n",
    "    Separa las variables de entrada y salida, normaliza los datos, divide en conjuntos de entrenamiento, validación y prueba,\n",
    "    y evalúa tres modelos diferentes (RandomForest, SVC, GradientBoostingClassifier) con validación cruzada.\n",
    "    \n",
    "    Parámetros:\n",
    "    data (pd.DataFrame): DataFrame de entrada.\n",
    "    target_column (str): Nombre de la columna objetivo.\n",
    "    \n",
    "    Retorna:\n",
    "    dict: Diccionario con los F1-Scores medios y sus intervalos de confianza del 95% para cada modelo.\n",
    "    \"\"\"\n",
    "    X = data.drop(target_column, axis=1)\n",
    "    y = data[target_column]\n",
    "    \n",
    "    sc = StandardScaler()\n",
    "    X = sc.fit_transform(X)\n",
    "    \n",
    "    # X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "    # X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val)\n",
    "    \n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(),\n",
    "        \"SupportVectorMachine\": SVC(),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier()\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        # f1_scorer = cross_val_score(model, X_train, y_train, cv=5)\n",
    "        f1_scorer = cross_val_score(model, X, y, cv=5)\n",
    "        media_f1 = f1_scorer.mean()\n",
    "        ci_95 = stats.t.interval(0.95, len(f1_scorer)-1, loc=media_f1, scale=stats.sem(f1_scorer))\n",
    "        \n",
    "        results[name] = {\n",
    "            \"F1-Score medio\": round(media_f1, 4),\n",
    "            \"Intervalo de confianza 95%\": (round(ci_95[0], 4), round(ci_95[1], 4))\n",
    "        }\n",
    "        \n",
    "        print(f\"{name} - F1-Score medio: {media_f1:.4f}\")\n",
    "        print(f\"{name} - Intervalo de confianza del 95%: ({ci_95[0]:.4f}, {ci_95[1]:.4f})\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procesamiento básico para para partir hacia todas las experimentaciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/Predict Hair Fall.csv')\n",
    "\n",
    "## Mapero de Si y No\n",
    "map_yes_no = {\n",
    "    \"Yes\": 1,\n",
    "    \"No\": 0\n",
    "}\n",
    "colums_yes_no = [\"Genetics\" ,\"Hormonal Changes\", \"Poor Hair Care Habits \", \"Environmental Factors\", \"Smoking\", \"Weight Loss \"]\n",
    "\n",
    "# Iterar por las columnas y mapear los valores\n",
    "for col in colums_yes_no:\n",
    "    if col in data.columns:  # Verifica que la columna exista\n",
    "        data[col] = data[col].map(map_yes_no)\n",
    "    else:\n",
    "        print(f\"Columna {col} no encontrada en el dataframe.\")\n",
    "\n",
    "# Mapeo estrés\n",
    "map_stres = {\n",
    "    \"Low\": 0,\n",
    "    \"Moderate\": 1,\n",
    "    \"High\": 2\n",
    "}\n",
    "data[\"Stress\"] = data[\"Stress\"].map(map_stres)\n",
    "\n",
    "# Eliminar ID: \n",
    "data.drop(\"Id\", axis = 1, inplace = True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1\n",
    "\n",
    "Agrupación de columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asignar_grupo(diccionario):\n",
    "    \"\"\"\n",
    "    Devuelve una función que asigna un grupo basado en el valor encontrado en el diccionario.\n",
    "    \"\"\"\n",
    "    def asignar(valor):\n",
    "        for grupo, valores in diccionario.items():\n",
    "            if valor in valores:\n",
    "                return grupo\n",
    "        return \"Otros\"  # Por seguridad\n",
    "    return asignar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data, columns):\n",
    "    \"\"\"\n",
    "    Aplica One-Hot Encoding a las columnas especificadas de un DataFrame.\n",
    "    \n",
    "    Parámetros:\n",
    "    data (pd.DataFrame): DataFrame de entrada.\n",
    "    columns (list): Lista de nombres de columnas a codificar.\n",
    "    \n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame con las columnas codificadas y eliminadas las originales.\n",
    "    \"\"\"\n",
    "    encoder = OneHotEncoder()\n",
    "    \n",
    "    for col in columns:\n",
    "        encoded = encoder.fit_transform(data[[col]]).toarray()\n",
    "        encoded_df = pd.DataFrame(encoded, columns=encoder.categories_[0])\n",
    "        \n",
    "        data = pd.concat([data, encoded_df], axis=1)\n",
    "        data.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupación de Medical Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = data.copy()\n",
    "exp11[\"Medical Conditions\"] = exp11[\"Medical Conditions\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_condiciones = {\n",
    "        \"Enfermedades inflamatorias de la piel\": [\"Eczema\", \"Psoriasis\", \"Dermatitis\", \"Seborrheic Dermatitis\"],\n",
    "        \"Infecciones\": [\"Ringworm\", \"Scalp Infection\"],\n",
    "        \"Trastornos del cabello\": [\"Alopecia Areata\", \"Androgenetic Alopecia\"],\n",
    "        \"Problemas sistémicos\": [\"Thyroid Problems\"],\n",
    "        \"Término genérico\": [\"Dermatosis\"],\n",
    "        \"No Data\": [\"No Data\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11[\"Grupo_Condiciones\"] = exp11[\"Medical Conditions\"].apply(asignar_grupo(grupos_condiciones))\n",
    "exp11.drop(\"Medical Conditions\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_onehotencoder = [\"Medications & Treatments\", \"Nutritional Deficiencies \", \"Grupo_Condiciones\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = one_hot_encode(exp11, columns_onehotencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_models(exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta agrupación parece mejorar los resultados de los modelos base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupación de Deficiendias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = data.copy()\n",
    "exp11[\"Nutritional Deficiencies \"] = exp11[\"Nutritional Deficiencies \"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_deficiencias = {\n",
    "        \"Vitaminas\": [\"Vitamin A Deficiency\", \"Vitamin D Deficiency\", \"Biotin Deficiency\", \"Vitamin E deficiency\"],\n",
    "        \"Minerales\": [\"Magnesium deficiency\", \"Selenium deficiency\", \"Zinc Deficiency\"],\n",
    "        \"Macronutrientes\": [\"Protein deficiency\"],\n",
    "        \"Ácidos grasos\": [\"Omega-3 fatty acids\"],\n",
    "        \"Sin deficiencia\": [\"No Data\", \"Iron deficiency\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11[\"Grupo Deficiencias\"] = exp11[\"Nutritional Deficiencies \"].apply(asignar_grupo(grupos_deficiencias))\n",
    "exp11.drop(\"Nutritional Deficiencies \",axis=1,inplace=True)\n",
    "columns_onehotencoder = [\"Medications & Treatments\", \"Grupo Deficiencias\", \"Medical Conditions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = one_hot_encode(exp11, columns_onehotencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_models(exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que esta agrupación puede mejorar las predicciones del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupación de Deficiendias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = data.copy()\n",
    "exp11[\"Medications & Treatments\"] = exp11[\"Medications & Treatments\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grupos_medicamentos = {\n",
    "        \"Antibióticos/Antifúngicos\": [\"Antibiotics\", \"Antifungal Cream\"],\n",
    "        \"Enfermedades crónicas\": [\"Blood Pressure Medication\", \"Heart Medication\"],\n",
    "        \"Inmunológicos\": [\"Immunomodulators\", \"Steroids\"],\n",
    "        \"Salud mental\": [\"Antidepressants\"],\n",
    "        \"Tratamientos para caída de cabello\": [\"Rogaine\", \"Accutane\"],\n",
    "        \"Quimioterapia\": [\"Chemotherapy\"],\n",
    "        \"No Data\": [\"No Data\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11[\"Grupo Medicamentos\"] = exp11[\"Medications & Treatments\"].apply(asignar_grupo(grupos_deficiencias))\n",
    "exp11.drop(\"Medications & Treatments\",axis=1,inplace=True)\n",
    "columns_onehotencoder = [\"Grupo Medicamentos\", \"Nutritional Deficiencies \", \"Medical Conditions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = one_hot_encode(exp11, columns_onehotencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_models(exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece mejorar la predicción del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Todas las agrupaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = data.copy()\n",
    "exp11[\"Medical Conditions\"] = exp11[\"Medical Conditions\"].str.strip()\n",
    "exp11[\"Grupo_Condiciones\"] = exp11[\"Medical Conditions\"].apply(asignar_grupo(grupos_condiciones))\n",
    "exp11.drop(\"Medical Conditions\",axis=1,inplace=True)\n",
    "exp11[\"Nutritional Deficiencies \"] = exp11[\"Nutritional Deficiencies \"].str.strip()\n",
    "exp11[\"Grupo Deficiencias\"] = exp11[\"Nutritional Deficiencies \"].apply(asignar_grupo(grupos_deficiencias))\n",
    "exp11.drop(\"Nutritional Deficiencies \",axis=1,inplace=True)\n",
    "exp11[\"Medications & Treatments\"] = exp11[\"Medications & Treatments\"].str.strip()\n",
    "exp11[\"Grupo Medicamentos\"] = exp11[\"Medications & Treatments\"].apply(asignar_grupo(grupos_deficiencias))\n",
    "exp11.drop(\"Medications & Treatments\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_onehotencoder = [\"Grupo_Condiciones\", \"Grupo Deficiencias\", \"Grupo Medicamentos\"]\n",
    "exp11 = one_hot_encode(exp11, columns_onehotencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_models(exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2\n",
    "Agrupar la edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear los bins para los grupos de edad\n",
    "bins = [0, 25, 35, 45, 60]\n",
    "\n",
    "# Definir las etiquetas para cada grupo\n",
    "labels = [0, 1, 2, 3]\n",
    "\n",
    "# Crear la nueva columna con los grupos de edad\n",
    "exp11['Age_group'] = pd.cut(exp11['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "exp11.drop(\"Age\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_onehotencoder = [\"Medical Conditions\", \"Nutritional Deficiencies \", \"Medications & Treatments\"]\n",
    "exp11 = one_hot_encode(exp11, columns_onehotencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_models(exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toda la experimentación junta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp11 = data.copy()\n",
    "exp11[\"Medical Conditions\"] = exp11[\"Medical Conditions\"].str.strip()\n",
    "exp11[\"Grupo_Condiciones\"] = exp11[\"Medical Conditions\"].apply(asignar_grupo(grupos_condiciones))\n",
    "exp11.drop(\"Medical Conditions\",axis=1,inplace=True)\n",
    "exp11[\"Nutritional Deficiencies \"] = exp11[\"Nutritional Deficiencies \"].str.strip()\n",
    "exp11[\"Grupo Deficiencias\"] = exp11[\"Nutritional Deficiencies \"].apply(asignar_grupo(grupos_deficiencias))\n",
    "exp11.drop(\"Nutritional Deficiencies \",axis=1,inplace=True)\n",
    "exp11[\"Medications & Treatments\"] = exp11[\"Medications & Treatments\"].str.strip()\n",
    "exp11[\"Grupo Medicamentos\"] = exp11[\"Medications & Treatments\"].apply(asignar_grupo(grupos_deficiencias))\n",
    "exp11.drop(\"Medications & Treatments\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear los bins para los grupos de edad\n",
    "bins = [0, 25, 35, 45, 60]\n",
    "\n",
    "# Definir las etiquetas para cada grupo\n",
    "labels = [0, 1, 2, 3]\n",
    "\n",
    "# Crear la nueva columna con los grupos de edad\n",
    "exp11['Age_group'] = pd.cut(exp11['Age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "\n",
    "exp11.drop(\"Age\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_onehotencoder = [\"Grupo_Condiciones\", \"Grupo Deficiencias\", \"Grupo Medicamentos\"]\n",
    "exp11 = one_hot_encode(exp11, columns_onehotencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = evaluate_models(exp11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = exp11.drop(\"Hair Loss\", axis=1)\n",
    "y = exp11[\"Hair Loss\"]\n",
    "    \n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Número de árboles en el ensamble\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],  # Tasa de aprendizaje\n",
    "    \"max_depth\": [3, 5, 7],  # Profundidad máxima de los árboles\n",
    "    \"subsample\": [0.8, 1.0],  # Proporción de muestras utilizadas para entrenar cada árbol\n",
    "    \"min_samples_split\": [2, 5, 10],  # Mínimo de muestras para dividir un nodo\n",
    "}\n",
    "\n",
    "# Configurar el Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',  # Usar 'f1_weighted' para manejar múltiples clases\n",
    "    cv=3,  # Validación cruzada con 5 pliegues\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación F1 (ponderada) en entrenamiento:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un modelo base SVM\n",
    "svm_model = SVC()\n",
    "\n",
    "# Definir los parámetros para Grid Search\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 1, 10],  # Controla la penalización del margen de error\n",
    "    \"kernel\": [\"linear\", \"rbf\", \"poly\"],  # Tipos de kernel disponibles\n",
    "    \"gamma\": [\"scale\", \"auto\", 0.01, 0.1],  # Solo aplicable a 'rbf' y 'poly'\n",
    "    \"degree\": [2, 3],  # Solo aplicable a 'poly'\n",
    "}\n",
    "\n",
    "# Configurar el Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Usar 'f1_weighted' para manejar múltiples clases\n",
    "    cv=3,  # Validación cruzada con 5 pliegues\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación F1 (ponderada) en entrenamiento:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],  # Número de árboles en el bosque\n",
    "    \"max_depth\": [None, 10, 20],  # Profundidad máxima de los árboles\n",
    "    \"min_samples_split\": [2, 5, 10],  # Mínimo de muestras para dividir un nodo\n",
    "    \"min_samples_leaf\": [1, 2, 4],  # Mínimo de muestras en una hoja\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],  # Número de características consideradas en cada división\n",
    "    \"bootstrap\": [True, False],  # Si se usa muestreo con reemplazo\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar el Grid Search\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',  # Usar 'f1_weighted' para manejar múltiples clases\n",
    "    cv=3,  # Validación cruzada con 5 pliegues\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación F1 (ponderada) en entrenamiento:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Staking de modelos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = [\n",
    "    ('gradient_boost', GradientBoostingClassifier(\n",
    "        learning_rate=0.2, max_depth=7, min_samples_split=2, \n",
    "        n_estimators=100, subsample=0.8)),\n",
    "    \n",
    "    ('svc', SVC(C=10, degree=3, gamma=0.1, kernel='poly', probability=True)),  # `probability=True` es necesario para Stacking\n",
    "    \n",
    "    ('random_forest', RandomForestClassifier(\n",
    "        bootstrap=True, max_depth=20, max_features='log2', \n",
    "        min_samples_leaf=1, min_samples_split=5, n_estimators=100))\n",
    "]\n",
    "\n",
    "# Meta-modelo (usamos regresión logística para combinar predicciones)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Definir el StackingClassifier\n",
    "stacking_clf = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=5, n_jobs=-1)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar en el conjunto de validación\n",
    "y_pred = stacking_clf.predict(X_val)\n",
    "\n",
    "# Calcular métricas de desempeño\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Stacking - F1 Score: {f1:.4f}\")\n",
    "print(f\"Stacking - Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def optimized_stacking(X, y):\n",
    "    \"\"\"\n",
    "    Realiza un Grid Search sobre los modelos base de un StackingClassifier y entrena el mejor modelo.\n",
    "\n",
    "    Parámetros:\n",
    "    X (array): Características de entrada.\n",
    "    y (array): Variable objetivo.\n",
    "\n",
    "    Retorna:\n",
    "    dict: Resultados del mejor modelo de stacking con F1-Score y Accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dividir datos en entrenamiento y validación\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "    # Definir los clasificadores base con opciones de hiperparámetros\n",
    "    base_estimators = {\n",
    "        \"gradient_boost\": GradientBoostingClassifier(),\n",
    "        \"svc\": SVC(probability=True),\n",
    "        \"random_forest\": RandomForestClassifier()\n",
    "    }\n",
    "\n",
    "    param_grid = {\n",
    "        \"gradient_boost__n_estimators\": [50, 100], \n",
    "        \"gradient_boost__learning_rate\": [0.1, 0.2],  \n",
    "        \"gradient_boost__max_depth\": [5, 7],  \n",
    "        \n",
    "        \"svc__C\": [1, 10],  \n",
    "        \"svc__kernel\": [\"poly\", \"rbf\"],  \n",
    "        \"svc__gamma\": [0.1, \"scale\"],  \n",
    "        \n",
    "        \"random_forest__n_estimators\": [50, 100],  \n",
    "        \"random_forest__max_depth\": [10, 20],  \n",
    "        \"random_forest__min_samples_split\": [2, 5]\n",
    "    }\n",
    "\n",
    "    # Definir el StackingClassifier\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=[(name, clf) for name, clf in base_estimators.items()],\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=3, n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Hacer Grid Search sobre los hiperparámetros de los modelos base\n",
    "    grid_search = GridSearchCV(\n",
    "        stacking_clf, param_grid, cv=3, scoring=\"f1\", n_jobs=-1, verbose=2\n",
    "    )\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el mejor modelo encontrado\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"Mejores parámetros: {grid_search.best_params_}\")\n",
    "    print(f\"Stacking - F1 Score: {f1:.4f}\")\n",
    "    print(f\"Stacking - Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"Mejores parámetros\": grid_search.best_params_,\n",
    "        \"F1 Score\": round(f1, 4),\n",
    "        \"Accuracy\": round(accuracy, 4)\n",
    "    }\n",
    "\n",
    "# Llamar a la función con X e y\n",
    "resultados = optimized_stacking(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Vemos que el mejor modelo es el ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
